{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole Game with Framestack as input\n",
    "end results: it always trains to only hold a certain action. i feel like the model also sees a correlation between the 2 actions. where 1 action will always have a lower q value than the other action. for example [-1, -4] are our predicted q values. if action 0 (-1) goes down for some reason action 1 (-4) also goes down and becomes something like this for example: [-8, -16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29.1\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(gymnasium.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    # Resize frame if needed\n",
    "    frame = cv2.resize(frame, (84, 84))\n",
    "    # Convert to grayscale\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Normalize pixel values\n",
    "    frame = frame / 255.0\n",
    "    # return\n",
    "    return frame\n",
    "\n",
    "def update_framestack(frame_stack, frame):\n",
    "    \"\"\"Moves every frame one place in the frame stack. starting on spot [0]. if the frame leaves spot [3], it gets removed from the frame stack. frame stack order [0] -> [1] -> [2] -> [3]\"\"\"\n",
    "    # update frame stack\n",
    "    frame_stack[:, :, 3] = frame_stack[:, :, 2]\n",
    "    frame_stack[:, :, 2] = frame_stack[:, :, 1]\n",
    "    frame_stack[:, :, 1] = frame_stack[:, :, 0]\n",
    "    frame_stack[:, :, 0] = frame\n",
    "    return frame_stack\n",
    "\n",
    "# def get_other_action(num):\n",
    "#     if num == 0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Environment\n",
    "# - we need render mode as rgb_array to get the values of the screen as np array\n",
    "env = gymnasium.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-network parameters\n",
    "stack_size = 4\n",
    "state_shape = (84, 84, 4)\n",
    "action_size = env.action_space.n\n",
    "\n",
    "# Q-network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (8, 8), strides=(4, 4),\n",
    "          activation='relu', input_shape=state_shape))\n",
    "model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(action_size, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=Adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Episode:0 Score:12.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Episode:1 Score:28.0\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Episode:2 Score:10.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Episode:3 Score:13.0\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Episode:4 Score:19.0\n",
      "16.4\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "episodes = 5  # amount of times we try to beat the game\n",
    "gamma = 0.1  # Discount factor\n",
    "exploration_rate = 1  # Exploration rate\n",
    "epsilon_decay = 0\n",
    "avg_score = 0\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "for episode in range(episodes):\n",
    "    # reset run\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    frame_stack = np.zeros((84, 84, stack_size))\n",
    "\n",
    "    # game loop\n",
    "    for i in range(200):\n",
    "        # GET STATE\n",
    "        # get screenshot of the game\n",
    "        frame = env.render()\n",
    "        # preprocess frame\n",
    "        frame_preprocessed = preprocess_frame(frame)\n",
    "        # update frame stack\n",
    "        frame_stack = update_framestack(frame_stack, frame_preprocessed)\n",
    "\n",
    "        # GET ACTION\n",
    "        # Exploration-exploitation strategy\n",
    "        if np.random.rand() <= exploration_rate:\n",
    "            action = env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            q_values = model.predict(np.reshape(frame_stack, (1, 84, 84, 4)))\n",
    "            action = np.argmax(q_values)  # Exploit\n",
    "\n",
    "        # DO ACTION\n",
    "        # do action\n",
    "        _, reward, dead, info, truncated = env.step(action)\n",
    "        # +1 score\n",
    "        score += reward\n",
    "        # punishment for dying\n",
    "        if dead:\n",
    "            reward = -20\n",
    "        # reward for completing\n",
    "        elif truncated:\n",
    "            reward = 100\n",
    "            dead = True\n",
    "        # reward for surviving\n",
    "        else:\n",
    "            reward = 5\n",
    "\n",
    "        # make a copy of the frame stack\n",
    "        new_frame_stack = frame_stack.copy()\n",
    "        # get new screenshot of the game\n",
    "        frame = env.render()\n",
    "        # preprocess frame\n",
    "        frame_preprocessed = preprocess_frame(frame)\n",
    "        # update frame stack\n",
    "        new_frame_stack = update_framestack(\n",
    "            new_frame_stack, frame_preprocessed)\n",
    "\n",
    "        # calucalte target q value with belman equation?\n",
    "        target = reward + gamma * \\\n",
    "            np.max(model.predict(np.reshape(new_frame_stack, (1, 84, 84, 4))))\n",
    "\n",
    "        # get current q_values\n",
    "        q_values = model.predict(np.reshape(frame_stack, (1, 84, 84, 4)))\n",
    "        # update the q_value so it takes into account the next states reward\n",
    "        q_values[0][action] = target\n",
    "        # Train the model on the updated Q-values\n",
    "        model.fit(np.reshape(frame_stack, (1, 84, 84, 4)),\n",
    "                  q_values, epochs=1, verbose=0)\n",
    "        if dead:\n",
    "            break\n",
    "    exploration_rate -= epsilon_decay\n",
    "    # print score\n",
    "    print(f'Episode:{episode} Score:{score}')\n",
    "    avg_score += score\n",
    "\n",
    "# print average score\n",
    "print(avg_score/episodes)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop (For Debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "[[-0.06939338 -0.0555506 ]]\n",
      "action: 1\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "target: 10.008665009588004\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "[[-0.06939338 -0.0555506 ]]\n",
      "[[-0.06939338 10.008665  ]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[ 0.0866501  -0.17163962]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "target: 10.019183726608754\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "[[ 0.0866501  -0.17163962]]\n",
      "[[10.019184   -0.17163962]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "[[ 0.19183727 -0.0972562 ]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "target: 10.026264607906342\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[ 0.19183727 -0.0972562 ]]\n",
      "[[10.026264  -0.0972562]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[[0.26264608 0.01641894]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "target: 10.026357659697533\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[0.26264608 0.01641894]]\n",
      "[[10.026358    0.01641894]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[0.2635766  0.01188509]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "target: 10.025933042168617\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[0.2635766  0.01188509]]\n",
      "[[10.025933    0.01188509]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "[[0.25933042 0.00280104]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "target: 10.02552001476288\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[0.25933042 0.00280104]]\n",
      "[[1.0025520e+01 2.8010365e-03]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[0.25520015 0.00374016]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "target: 10.025456416606904\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[[0.25520015 0.00374016]]\n",
      "[[1.0025456e+01 3.7401617e-03]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[0.25456417 0.0128191 ]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "target: 10.025362983345985\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[[0.25456417 0.0128191 ]]\n",
      "[[10.025363   0.0128191]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[0.25362983 0.02802707]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "target: 10.025101724267007\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[0.25362983 0.02802707]]\n",
      "[[10.025102    0.02802707]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[[0.25101724 0.0233124 ]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: 10\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "target: 10.02471071779728\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "[[0.25101724 0.0233124 ]]\n",
      "[[10.024711   0.0233124]]\n",
      "\n",
      "Model Predicting------\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[0.24710718 0.01918482]]\n",
      "action: 0\n",
      "Do Action-----\n",
      "initial reward: 1.0\n",
      "modified reward: -20\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "target: -19.976150810718536\n",
      "Reprediction Model------\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "[[0.24710718 0.01918482]]\n",
      "[[-1.9976151e+01  1.9184824e-02]]\n",
      "\n",
      "Episode:0 Score:11.0\n",
      "11.0\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "episodes = 1  # amount of times we try to beat the game\n",
    "gamma = 0.1  # Discount factor // idk what gamma does\n",
    "exploration_rate = 0  # Exploration rate\n",
    "epsilon_decay = 0\n",
    "min_epsilon = 0.01\n",
    "stack_size = 4\n",
    "avg_score = 0\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "for episode in range(episodes):\n",
    "    # reset run\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    frame_stack = np.zeros((84, 84, stack_size))\n",
    "\n",
    "    # game loop\n",
    "    for i in range(200):\n",
    "        # GET STATE\n",
    "        # get screenshot of the game\n",
    "        frame = env.render()\n",
    "        # preprocess frame\n",
    "        frame_preprocessed = preprocess_frame(frame)\n",
    "        # update frame stack\n",
    "        frame_stack = update_framestack(frame_stack, frame_preprocessed)\n",
    "\n",
    "        # GET ACTION\n",
    "        # Exploration-exploitation strategy\n",
    "        if np.random.rand() <= exploration_rate:\n",
    "            action = env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            print(\"Model Predicting------\")\n",
    "            q_values = model.predict(np.reshape(frame_stack, (1, 84, 84, 4)))\n",
    "            print(q_values)\n",
    "            action = np.argmax(q_values)  # Exploit\n",
    "            print(f'action: {action}')\n",
    "\n",
    "        # DO ACTION\n",
    "        # do action\n",
    "        print(\"Do Action-----\")\n",
    "        _, reward, dead, info, truncated = env.step(action)\n",
    "        print(f'initial reward: {reward}')\n",
    "        # +1 score\n",
    "        score += reward\n",
    "        # punishment for dying\n",
    "        if dead:\n",
    "            reward = -20\n",
    "        # reward for completing\n",
    "        elif truncated:\n",
    "            reward = 10\n",
    "            dead = True\n",
    "        else:\n",
    "            reward=10\n",
    "        print(f'modified reward: {reward}')\n",
    "\n",
    "        # make a copy of the frame stack\n",
    "        new_frame_stack = frame_stack.copy()\n",
    "        # get new screenshot of the game\n",
    "        frame = env.render()\n",
    "        # preprocess frame\n",
    "        frame_preprocessed = preprocess_frame(frame)\n",
    "        # update frame stack\n",
    "        new_frame_stack = update_framestack(\n",
    "            new_frame_stack, frame_preprocessed)\n",
    "\n",
    "        # calucalte target q value with belman equation?\n",
    "        target = reward + gamma * np.max(model.predict(np.reshape(new_frame_stack, (1, 84, 84, 4))))\n",
    "        print(f'target: {target}')\n",
    "\n",
    "        # get current q_values\n",
    "        print('Reprediction Model------')\n",
    "        q_values = model.predict(np.reshape(frame_stack, (1, 84, 84, 4)))\n",
    "        print(q_values)\n",
    "        # update the q_value so it takes into account the next states reward\n",
    "        q_values[0][action] = target\n",
    "        print(q_values)\n",
    "        # Train the model on the updated Q-values\n",
    "        # model.fit(np.reshape(frame_stack, (1, 84, 84, 4)),q_values, epochs=1, verbose=0)\n",
    "        print()\n",
    "        if dead:\n",
    "            break\n",
    "    exploration_rate-=epsilon_decay\n",
    "    # print score\n",
    "    print(f'Episode:{episode} Score:{score}')\n",
    "    avg_score += score\n",
    "\n",
    "# print average score\n",
    "print(avg_score/episodes)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Frame Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(frame_stack[:, :, stack_size-i-1], cmap='gray')  # Assuming grayscale images\n",
    "    plt.title('Image: ' + str(i+1))\n",
    "\n",
    "# Adjust layout for better visualization\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Prediction on the Last Frame Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.6672783, -8.217273 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.reshape(frame_stack, (1, 84, 84, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./data/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
